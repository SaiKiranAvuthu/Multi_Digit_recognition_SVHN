{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Digit Recognition\n",
    "\n",
    "This notebook shown the a simply model in keras to recognize a digit sequence in a real world image. This images data is taken from the Street View House Number Dataset. This model is divided into two part.**Preprocessing** notebook consist of converting the images in the dataset to 32x32 greyscale images array and save it in the h5 file.**Multi Digit Recognition** notebook consists of CNN model to predict the multi digit number in the images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets import the main packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiki\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Lambda,Dense,Dropout,Activation,Flatten,Conv2D,MaxPooling2D\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the data from the h5 file created in the preprocessing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (230754, 32, 32, 1) (230754, 5)\n",
      "Validation set (5000, 32, 32, 1) (5000, 5)\n",
      "Test set      (13068, 32, 32, 1) (13068, 5)\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('data/svhn_multi_grey.h5','r')\n",
    "\n",
    "# Extract the datasets\n",
    "x_train = h5f['train_dataset'][:]\n",
    "y_train = h5f['train_labels'][:]\n",
    "x_val = h5f['valid_dataset'][:]\n",
    "y_val = h5f['valid_labels'][:]\n",
    "x_test = h5f['test_dataset'][:]\n",
    "y_test = h5f['test_labels'][:]\n",
    "\n",
    "# Close the file\n",
    "h5f.close()\n",
    "\n",
    "print('Training set', x_train.shape, y_train.shape)\n",
    "print('Validation set', x_val.shape, y_val.shape)\n",
    "print('Test set     ', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I merge the validation set into the training set and shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate([x_train, x_val])\n",
    "Y_train = np.concatenate([y_train, y_val])\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Randomly shuffle the training data\n",
    "\n",
    "X_train, Y_train = shuffle(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the data is done for getting the better results and reduce the time to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_mean(a):\n",
    "    \"\"\" Helper function for subtracting the mean of every image\n",
    "    \"\"\"\n",
    "    for i in range(a.shape[0]):\n",
    "        a[i] -= a[i].mean()\n",
    "    return a\n",
    "\n",
    "\n",
    "# Subtract the mean from every image\n",
    "X_train = subtract_mean(X_train)\n",
    "X_test = subtract_mean(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Helper function to convert the number into one hot encoding for each digit and combining the into one array of length 55\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the y data\n",
    "def y_data_transform(y):\n",
    "    y_new=np.zeros((y.shape[0],y.shape[1]*11),dtype=\"int\")\n",
    "    for (i,j),l in np.ndenumerate(y):\n",
    "        y_new[i,j*11+l]=1\n",
    "    return y_new\n",
    "Y_Train=y_data_transform(Y_train)\n",
    "Y_test=y_data_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model created using keras input model. The following model summary is the main model for the recognition the number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        51264     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         204928    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         409728    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 128)         409728    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 253)               65021     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 55)                13970     \n",
      "=================================================================\n",
      "Total params: 3,380,975\n",
      "Trainable params: 3,380,975\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_data=Input(name=\"input\",shape=(32,32,1),dtype='float32')\n",
    "conv1=Conv2D(32,5,padding=\"same\",activation=\"relu\")(input_data)\n",
    "conv2=Conv2D(32,5,padding=\"same\",activation=\"relu\")(conv1)\n",
    "max1=MaxPooling2D(pool_size=(2, 2),padding=\"same\")(conv2)\n",
    "drop1=Dropout(0.75)(max1)\n",
    "\n",
    "conv3=Conv2D(64,5,padding=\"same\",activation=\"relu\")(drop1)\n",
    "conv4=Conv2D(64,5,padding=\"same\",activation=\"relu\")(conv3)\n",
    "max2=MaxPooling2D(pool_size=(2, 2),padding=\"same\")(conv4)\n",
    "drop2=Dropout(0.75)(max2)\n",
    "\n",
    "conv5=Conv2D(128,5,padding=\"same\",activation=\"relu\")(drop2)\n",
    "conv6=Conv2D(128,5,padding=\"same\",activation=\"relu\")(conv5)\n",
    "conv7=Conv2D(128,5,padding=\"same\",activation=\"relu\")(conv6)\n",
    "flat=Flatten()(conv7)\n",
    "\n",
    "fc1=Dense(256,activation=\"relu\")(flat)\n",
    "drop3=Dropout(0.5)(fc1)\n",
    "fc2=Dense(253,activation=\"relu\")(drop3)\n",
    "output=Dense(55,activation=\"sigmoid\")(fc2)\n",
    "\n",
    "model1=Model(inputs=input_data, outputs=output)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom Loss Function**\n",
    "  This is the custom loss function created to compare the y_predicted to y actual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_EPSILON=1e-7\n",
    "def _loss_tensor(y_true, y_pred):\n",
    "    y_pred = K.clip(y_pred, _EPSILON, 1.0-_EPSILON)\n",
    "    out = -(y_true * K.log(y_pred) + (1.0 - y_true) * K.log(1.0 - y_pred))\n",
    "    return K.mean(out, axis=-1)\n",
    "def loss_func(y):\n",
    "    y_pred,y_true=y\n",
    "    loss=_loss_tensor(y_true,y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Lambda layer with the loss function with the Y_true value to caluculating loss and the output of this layer is the loss value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "y_true = Input(name='y_true', shape=[55], dtype='float32')\n",
    "\n",
    "loss_out = Lambda(loss_func, output_shape=(1,), name='loss')([output, y_true])\n",
    "\n",
    "model = Model(inputs=[input_data,y_true], outputs=loss_out)\n",
    "\n",
    "model.add_loss(K.sum(loss_out,axis=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding the loss function to the last layer, loss function is kept to none in the compiler so that the value from the  layer is to tend to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "235754/235754 [==============================] - 116s 493us/step - loss: 193.0511\n",
      "Epoch 2/25\n",
      "235754/235754 [==============================] - 110s 465us/step - loss: 161.9264\n",
      "Epoch 3/25\n",
      "235754/235754 [==============================] - 110s 466us/step - loss: 150.3311\n",
      "Epoch 4/25\n",
      "235754/235754 [==============================] - 111s 470us/step - loss: 131.5419\n",
      "Epoch 5/25\n",
      "235754/235754 [==============================] - 112s 473us/step - loss: 109.1504\n",
      "Epoch 6/25\n",
      "235754/235754 [==============================] - 110s 469us/step - loss: 87.3990\n",
      "Epoch 7/25\n",
      "235754/235754 [==============================] - 110s 467us/step - loss: 68.9336\n",
      "Epoch 8/25\n",
      "235754/235754 [==============================] - 110s 467us/step - loss: 56.4606\n",
      "Epoch 9/25\n",
      "235754/235754 [==============================] - 110s 467us/step - loss: 48.6544\n",
      "Epoch 10/25\n",
      "235754/235754 [==============================] - 110s 467us/step - loss: 43.7350\n",
      "Epoch 11/25\n",
      "235754/235754 [==============================] - 111s 471us/step - loss: 40.2667\n",
      "Epoch 12/25\n",
      "235754/235754 [==============================] - 110s 467us/step - loss: 37.4090\n",
      "Epoch 13/25\n",
      "235754/235754 [==============================] - 111s 472us/step - loss: 35.1917\n",
      "Epoch 14/25\n",
      "235754/235754 [==============================] - 112s 474us/step - loss: 33.6588\n",
      "Epoch 15/25\n",
      "235754/235754 [==============================] - 112s 475us/step - loss: 31.7385\n",
      "Epoch 16/25\n",
      "235754/235754 [==============================] - 126s 535us/step - loss: 30.1490\n",
      "Epoch 17/25\n",
      "235754/235754 [==============================] - 126s 535us/step - loss: 29.1520\n",
      "Epoch 18/25\n",
      "235754/235754 [==============================] - 126s 536us/step - loss: 27.9035\n",
      "Epoch 19/25\n",
      "235754/235754 [==============================] - 126s 535us/step - loss: 26.9709\n",
      "Epoch 20/25\n",
      "235754/235754 [==============================] - 126s 535us/step - loss: 26.5437\n",
      "Epoch 21/25\n",
      "235754/235754 [==============================] - 126s 535us/step - loss: 25.7282\n",
      "Epoch 22/25\n",
      "235754/235754 [==============================] - 126s 535us/step - loss: 25.1414\n",
      "Epoch 23/25\n",
      "235754/235754 [==============================] - 126s 535us/step - loss: 24.6235\n",
      "Epoch 24/25\n",
      "235754/235754 [==============================] - 126s 535us/step - loss: 24.3906\n",
      "Epoch 25/25\n",
      "235754/235754 [==============================] - 126s 534us/step - loss: 24.1711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x164fc742ef0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_board = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "model.compile(loss=None, optimizer=\"adam\", loss_weights=None)\n",
    "\n",
    "model.fit(x=[X_train,Y_Train],y=None, batch_size=1000, epochs=25, verbose=1,callbacks=[tensor_board])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss value is seem big because of the custom function created and accuracy caluculated below shows the accuracy in detecting rigth digits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.23456481099129\n"
     ]
    }
   ],
   "source": [
    "Accuracy=(1-np.mean(model.predict([X_test[:],Y_test[:]])))*100\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"MDR_model.h5\")\n",
    "model.save_weights(\"MDR_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helper function will convert the logits of 55 into number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_num(x):\n",
    "    num=\"\"\n",
    "    if len(x)==55:\n",
    "        for i in range(5):\n",
    "            c=np.argmax(x[i*11:(i+1)*11])\n",
    "            if c!=10:\n",
    "                num+=str(c)\n",
    "        return num\n",
    "    else:\n",
    "        print(\"This function might not be used that way\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even thought the accuracy for each digit is high, the accuracy for predicting the full number is lowered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error 1561  out of  13068 and total accuracy 88.0547903275176\n"
     ]
    }
   ],
   "source": [
    "X1=model1.predict(X_test)\n",
    "Y1=Y_test\n",
    "j=0\n",
    "for i in range(len(X_test)):\n",
    "    try:\n",
    "        \n",
    "        if eval(convert_to_num(X1[i]))!=eval(convert_to_num(Y1[i])):\n",
    "            j+=1\n",
    "            #print(i,[convert_to_num(X1[i]),convert_to_num(Y1[i])])\n",
    "    except:\n",
    "        j+=1\n",
    "print(\"total error\",j,\" out of \",len(X1),\"and total accuracy\",(1-(j/len(X1)))*100)\n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
